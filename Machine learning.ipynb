{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Загрузка файлов"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загрузка файлов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "\n",
    "file1 = files.upload()\n",
    "file2 = files.upload()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Чтение файлов (и импорт библиотек)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "import numpy\n",
    "\n",
    "training_set=pandas.read_csv('/content/UNSW_NB15_training-set.csv') \n",
    "testing_set=pandas.read_csv('/content/UNSW_NB15_testing-set.csv') \n",
    "\n",
    "data = pandas.concat([training_set, testing_set]).reset_index(drop=True)\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверка сбалансированности данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "values_counts = data['label'].value_counts()\n",
    "print(values_counts)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Обработка данных"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Удаление колонок с повреждёнными данными"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.loc[data['proto'] == 'any', 'proto'] = None\n",
    "data.loc[data['proto'] == 'unas', 'proto'] = None\n",
    "\n",
    "column_names = data.columns.values.tolist()\n",
    "\n",
    "for column_name in column_names:\n",
    "    if len(data[column_name].dropna()) / len(data) < 0.8:\n",
    "        if column_name != \"label\":\n",
    "            del data[column_name]\n",
    "        else:\n",
    "            print(\"Label was deleted\")\n",
    "\n",
    "print(len(column_names))\n",
    "print(len(data.columns.values.tolist()))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Удаление колонок с не нужными данными"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = data.columns.values.tolist()\n",
    "\n",
    "del data['attack_cat']\n",
    "del data['id']\n",
    "\n",
    "print(len(column_names))\n",
    "print(len(data.columns.values.tolist()))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Удаление противоречащих и дублирующихся данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Data length before deletion \" + str(len(data)))\n",
    "\n",
    "data = data.drop_duplicates(subset=data.columns.values.tolist().remove('label'), ignore_index=True)\n",
    "\n",
    "print(\"Data length after deletion \" + str(len(data)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Кодирование категориальных признаков"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "column_names = data.columns.values.tolist()\n",
    "\n",
    "encoder = OneHotEncoder(handle_unknown='ignore',sparse=False)\n",
    "\n",
    "encoder.fit(data[['proto']])\n",
    "\n",
    "encoded_protocols = pandas.DataFrame(encoder.transform(data[['proto']]))\n",
    "encoded_protocols.columns = encoder.get_feature_names_out()\n",
    "\n",
    "data = data.join(encoded_protocols)\n",
    "\n",
    "encoder.fit(data[['service']])\n",
    "\n",
    "encoded_services = pandas.DataFrame(encoder.transform(data[['service']]))\n",
    "encoded_services.columns = encoder.get_feature_names_out()\n",
    "\n",
    "data = data.join(encoded_services)\n",
    "\n",
    "encoder.fit(data[['state']])\n",
    "\n",
    "encoded_states = pandas.DataFrame(encoder.transform(data[['state']]))\n",
    "encoded_states.columns = encoder.get_feature_names_out()\n",
    "\n",
    "data = data.join(encoded_states)\n",
    "\n",
    "del data['proto']\n",
    "del data['service']\n",
    "del data['state']\n",
    "\n",
    "print(len(column_names))\n",
    "print(len(data.columns.values.tolist()))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Удаление аномалий"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "X = data.drop(columns=['label'])\n",
    "X = IsolationForest().fit_predict(X)\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "pcs = pca.fit_transform(data)\n",
    "pcDf = pandas.DataFrame(data = pcs [:, 0:2], columns = ['pc 1', 'pc 2'])\n",
    "output = pandas.concat([pcDf, pandas.DataFrame(data = X, columns=['is_anomaly'])], axis = 1)\n",
    "\n",
    "mask = X == -1\n",
    "\n",
    "print(\"Data length before deletion \" + str(len(data)))\n",
    "\n",
    "data = data.drop(data[mask].index).reset_index(drop=True)\n",
    "\n",
    "print(\"Data length before deletion \" + str(len(data)))\n",
    "\n",
    "plt.figure()\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.xticks(fontsize=12)\n",
    "plt.yticks(fontsize=14)\n",
    "plt.xlabel('Principal Component - 1',fontsize=20)\n",
    "plt.ylabel('Principal Component - 2',fontsize=20)\n",
    "plt.title(\"2 Principal Component Analysis of  Dataset\",fontsize=20)\n",
    "targets = [1,-1]\n",
    "colors = ['g', 'r']\n",
    "for target, color in zip(targets,colors):\n",
    "    indicesToKeep = output['is_anomaly'] == target\n",
    "    plt.scatter(output.loc[indicesToKeep, 'pc 1']\n",
    "               , output.loc[indicesToKeep, 'pc 2'], c = color, s = 50)\n",
    "\n",
    "plt.legend(targets,prop={'size': 15})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Заполнение пропусков"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import mean\n",
    "\n",
    "data = data.fillna(data.apply(lambda column: mean(column.dropna()), axis=0))\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разделение на X и Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop(columns=['label'])\n",
    "Y = data['label']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Удаление неинформативных признаков"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "model = DecisionTreeClassifier()\n",
    "model.fit(X, Y)\n",
    "importances = model.feature_importances_\n",
    "importances = pandas.Series(importances, index=data.columns[1:])\n",
    "importances = {\n",
    "    \"feature\": importances.index.to_list(),\n",
    "    \"importance\": importances.values\n",
    "}\n",
    "importances = pandas.DataFrame(importances)\n",
    "importances = importances[importances[\"importance\"] < 0.00005][\"feature\"].tolist()\n",
    "if \"label\" in importances:\n",
    "  importances.remove(\"label\")\n",
    "\n",
    "column_names = data.columns.values.tolist()\n",
    "\n",
    "X = X.drop(columns=importances)\n",
    "\n",
    "print(len(column_names))\n",
    "print(len(X.columns.values.tolist()))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Удаление констант"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = X.columns.values.tolist()\n",
    "\n",
    "for column_name in column_names:\n",
    "    counted = X[column_name].value_counts()\n",
    "    if counted.values[0] / len(X) > 0.8:\n",
    "        del X[column_name]\n",
    "      \n",
    "    \n",
    "print(len(column_names))\n",
    "print(len(X.columns.values.tolist()))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Стандартизация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "scaler = preprocessing.StandardScaler()\n",
    "scaler = scaler.fit(X)\n",
    "data = scaler.transform(X)\n",
    "X = pandas.DataFrame(data, columns=X.columns)\n",
    "\n",
    "X.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Центирование"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.apply(lambda x: x-x.mean())\n",
    "\n",
    "X.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Нормализация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pandas.DataFrame(preprocessing.normalize(X), columns=X.columns)\n",
    "\n",
    "X.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверка сбалансированости данных №2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "values_counts = Y.value_counts()\n",
    "print(values_counts)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Балансировка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "training_X, testing_X, training_Y, testing_Y = train_test_split(X, Y, test_size=0.33)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверка сбалансированости данных №3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "values_counts = training_Y.value_counts()\n",
    "print(values_counts)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Визуализация данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=2)\n",
    "X_pca = pca.fit_transform(X)\n",
    "\n",
    "unique_labels = numpy.unique(Y)\n",
    "colors = ['g', 'r']\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "for label in unique_labels:\n",
    "    indices = numpy.where(Y == label)\n",
    "    plt.scatter(X_pca[indices, 0], X_pca[indices, 1], color=colors[label], label=label)\n",
    "\n",
    "plt.xlabel('Principal Component 1')\n",
    "plt.ylabel('Principal Component 2')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Создание моделей"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Общие импорты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "import seaborn as sns"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bagging Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "model = BaggingClassifier()\n",
    "\n",
    "model.fit(training_X,training_Y)\n",
    "predicted_Y = model.predict(testing_X)\n",
    "\n",
    "# confusion matrix\n",
    "cm = confusion_matrix(predicted_Y, testing_Y)\n",
    "sns.heatmap(cm, annot=True, cmap='Blues')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.show()\n",
    "\n",
    "# classification report\n",
    "report = classification_report(predicted_Y, testing_Y)\n",
    "print(report)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gradient Boosting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "\n",
    "model = GradientBoostingClassifier()\n",
    "\n",
    "model.fit(training_X,training_Y)\n",
    "predicted_Y = model.predict(testing_X)\n",
    "\n",
    "# confusion matrix\n",
    "cm = confusion_matrix(predicted_Y, testing_Y)\n",
    "sns.heatmap(cm, annot=True, cmap='Blues')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.show()\n",
    "\n",
    "# classification report\n",
    "report = classification_report(predicted_Y, testing_Y)\n",
    "print(report)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "model = RandomForestClassifier()\n",
    "\n",
    "model.fit(training_X,training_Y)\n",
    "predicted_Y = model.predict(testing_X)\n",
    "\n",
    "# confusion matrix\n",
    "cm = confusion_matrix(predicted_Y, testing_Y)\n",
    "sns.heatmap(cm, annot=True, cmap='Blues')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.show()\n",
    "\n",
    "# classification report\n",
    "report = classification_report(predicted_Y, testing_Y)\n",
    "print(report)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
